{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "class learnable_quad_curve:\n",
    "    def __init__(self, learning_rate):\n",
    "        self.lr = learning_rate\n",
    "        self.a = np.random.random()\n",
    "        self.b = np.random.random()\n",
    "        self.c = np.random.random()\n",
    "        \n",
    "    def evaluate(self, x):\n",
    "        return x * x * self.a + x * self.b + np.ones_like(x) * self.c\n",
    "    \n",
    "    def fit(self, x, y):\n",
    "        y_pred = self.evaluate(x)\n",
    "        n_points = len(x)\n",
    "        loss = np.sum(np.power((y_pred - y), 2.0)) / n_points\n",
    "        ga = -2 * np.add.reduce((y_pred - y) * x * x) / n_points\n",
    "        gb = -2 * np.add.reduce((y_pred - y) * x) / n_points\n",
    "        gc = -2 * np.add.reduce(y_pred - y) / n_points\n",
    "        self.a = self.a + self.lr * ga \n",
    "        self.b = self.b + self.lr * gb\n",
    "        self.c = self.c + self.lr * gc\n",
    "        return loss\n",
    "        \n",
    "    def show(self):\n",
    "        print \"a = \", self.a\n",
    "        print \"b = \", self.b\n",
    "        print \"c = \", self.c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(training_x, training_y, lr, epochs, batch_size):\n",
    "    model = learnable_quad_curve(learning_rate=lr)\n",
    "    for k in range(epochs):\n",
    "        total_loss = 0\n",
    "        for s in range(0, len(training_x), batch_size):\n",
    "            x = training_x[s:s+batch_size]\n",
    "            y = training_y[s:s+batch_size]\n",
    "            loss = model.fit(x, y)\n",
    "            #print loss\n",
    "            total_loss += loss/1000.0\n",
    "        if k%10000 == 0:\n",
    "            print \"loss = \", total_loss\n",
    "            sys.stdout.flush()\n",
    "        if total_loss <= 0.01:\n",
    "            break\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss =  18986.917450096007\n",
      "loss =  0.1584842376849841\n",
      "loss =  0.13667812033967294\n",
      "loss =  0.11787234457720547\n",
      "loss =  0.10165408928274654\n",
      "loss =  0.08766733388715468\n",
      "loss =  0.0756050431175663\n",
      "loss =  0.06520242705765258\n",
      "loss =  0.056231128561602034\n",
      "loss =  0.04849421042968334\n",
      "loss =  0.041821832302224256\n",
      "loss =  0.03606752237471903\n",
      "loss =  0.03110496209167262\n",
      "loss =  0.026825213238056488\n",
      "loss =  0.02313432655740216\n",
      "loss =  0.019951279403742327\n",
      "loss =  0.017206197153523034\n",
      "loss =  0.014838819335621494\n",
      "loss =  0.012797176808314378\n",
      "loss =  0.011036450944790117\n",
      "a =  2.0003930880177085\n",
      "b =  4.990578677880503\n",
      "c =  2.4966092727189686\n"
     ]
    }
   ],
   "source": [
    "EPOCHS=200000\n",
    "LEARNING_RATE=1e-7\n",
    "BATCH_SIZE = 100\n",
    "x = np.linspace(-50, 50, 10000)\n",
    "noise = np.random.random((len(x))) * 0.01 - 0.005\n",
    "y = x*x*2 + x*5 + np.ones_like(x)*3 + noise\n",
    "model = train(x, y, lr=LEARNING_RATE, epochs=EPOCHS, batch_size=BATCH_SIZE)\n",
    "model.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
